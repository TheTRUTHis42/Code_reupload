{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final-Multitask_BERT_with_GLUE(2tasks: wnli&mrpc).ipynb（副本）","provenance":[{"file_id":"16GPjgC2AbxOcu_mQi3Tq80uaOgtDybb2","timestamp":1631783218474},{"file_id":"1iSetM7v5HT8EXvrxn7L20OF2YEYtUKZS","timestamp":1631773836636},{"file_id":"1YRWPMQgeP9NSNQ0N8N-qeQm00luoFM5M","timestamp":1631637710152}],"collapsed_sections":[],"authorship_tag":"ABX9TyOiOOCGuiCYyFbY7at05eEL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9f00116af98e48508bc4a1e1691e1a85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c3221c8581a547c5a7aad7411b55f5dc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2c16ef2863e54f52b654de849f78fb80","IPY_MODEL_e6f64497c3024c22937058dd712c9f32","IPY_MODEL_7384aaf85c0d45beb9666208362394a8"]}},"c3221c8581a547c5a7aad7411b55f5dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c16ef2863e54f52b654de849f78fb80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_187ef0e2eb034f4c901ebf96c721f7cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fc08c1275af4c6eb7dc5ef9025bba5e"}},"e6f64497c3024c22937058dd712c9f32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cf62791e398b4c17a17709c9202005f7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":7777,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7777,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d013b4e6f7d74e4b9daf71b983b20cd6"}},"7384aaf85c0d45beb9666208362394a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8270cbe58c9d4078812de27b8e013c27","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.8k/? [00:00&lt;00:00, 718kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2dce3596e3914fd091dc5cdba816e536"}},"187ef0e2eb034f4c901ebf96c721f7cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fc08c1275af4c6eb7dc5ef9025bba5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf62791e398b4c17a17709c9202005f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d013b4e6f7d74e4b9daf71b983b20cd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8270cbe58c9d4078812de27b8e013c27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2dce3596e3914fd091dc5cdba816e536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64663b49094746ee9a279adee02818c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dc2430b4c25247a0b0f8d9ed22113c99","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_84099942eb80488699684742ad8e5791","IPY_MODEL_ee8bd466c2c74124b5b8e08c3cd88e38","IPY_MODEL_d0ade1011e3d45e597465e6337bbf7d9"]}},"dc2430b4c25247a0b0f8d9ed22113c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84099942eb80488699684742ad8e5791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_237011ca2b604433b2b18d8612198245","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f54704fc3204ca79f110d107aaf7cc5"}},"ee8bd466c2c74124b5b8e08c3cd88e38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_04d1cae2d98c48169a9256cba4d094c8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ccb7d8eb45049efbe25740e01f6ca5a"}},"d0ade1011e3d45e597465e6337bbf7d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7667b55ec10e4a7491d64d44a3d46bbc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  4.17ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_878d7a772e5f4b12aaaf618e96b2d3de"}},"237011ca2b604433b2b18d8612198245":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f54704fc3204ca79f110d107aaf7cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04d1cae2d98c48169a9256cba4d094c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ccb7d8eb45049efbe25740e01f6ca5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7667b55ec10e4a7491d64d44a3d46bbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"878d7a772e5f4b12aaaf618e96b2d3de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cbefa5229f24885a846f41a70051e03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a8a9d8a7950f4a10947694dc0502ba8a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1176bb6efa364ec78904bd1f86620253","IPY_MODEL_b9e52956c6df4efa974a6e6f69c96d63","IPY_MODEL_5543e4ca4c0a4c7a839abf1259456ecd"]}},"a8a9d8a7950f4a10947694dc0502ba8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1176bb6efa364ec78904bd1f86620253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b846418ad514b48b2de6f8ea47625ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f97835a89799477486d39c4ceae4eb0e"}},"b9e52956c6df4efa974a6e6f69c96d63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c4813290fc294acfa98d228284c1a6d2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1f23bdc605c40e9b41c02345ca7eb5d"}},"5543e4ca4c0a4c7a839abf1259456ecd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_215806e166e54950a4b2fc3dfb81a368","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [09:02&lt;00:00, 54.14s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94845e7b34234da4ae9ae41d65f69a53"}},"3b846418ad514b48b2de6f8ea47625ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f97835a89799477486d39c4ceae4eb0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4813290fc294acfa98d228284c1a6d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1f23bdc605c40e9b41c02345ca7eb5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"215806e166e54950a4b2fc3dfb81a368":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94845e7b34234da4ae9ae41d65f69a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03642103586a428180c63d1e39422e4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c5dcc6c59f54366ad98308d4da7ab4a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0882a52ffcfd41abb5ac64428434a598","IPY_MODEL_bf3f7ba5ef6f4276a3f8f4ebb0d731d2","IPY_MODEL_e554e99b59924b419bcb1ccd318bd933"]}},"9c5dcc6c59f54366ad98308d4da7ab4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0882a52ffcfd41abb5ac64428434a598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b372cc9a64c47339dd8d89066b3ea8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Iteration: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af95cc3a9e3245cab4cf9cab0b665a05"}},"bf3f7ba5ef6f4276a3f8f4ebb0d731d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3640993c13764216b859778613b410e8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":135,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":135,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb8c794f3ba544dab5b686223d033df2"}},"e554e99b59924b419bcb1ccd318bd933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0b3baa699484437a82b8b10b0a0221b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 135/135 [00:54&lt;00:00,  2.75it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59b6f84155cd47179d82435acd4b0abe"}},"7b372cc9a64c47339dd8d89066b3ea8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"af95cc3a9e3245cab4cf9cab0b665a05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3640993c13764216b859778613b410e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fb8c794f3ba544dab5b686223d033df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0b3baa699484437a82b8b10b0a0221b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"59b6f84155cd47179d82435acd4b0abe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd142ea1bc08489bb07faa2d2e3551b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3568f3b6fd54465aa74eff13c381fc25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81b2a8812c3840be9408a4f51c9a8e5f","IPY_MODEL_1d47186eb8ff42699b04b9a4a3aa9584","IPY_MODEL_1e6340e29f094983818e12839502de92"]}},"3568f3b6fd54465aa74eff13c381fc25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81b2a8812c3840be9408a4f51c9a8e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc92fcb339584275acc290d2be9393ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7b63d7d9c4b4f35a4e999f2e177cbcd"}},"1d47186eb8ff42699b04b9a4a3aa9584":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d4187bf2bd04b28a051e901a41f160d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4151,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4151,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f57a2720b21b46e492752e65b3e70470"}},"1e6340e29f094983818e12839502de92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_97874ea40bce42c6838822a040bf7e80","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.15k/4.15k [00:00&lt;00:00, 134kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5007898e6ccd4d0da057708174816cf0"}},"fc92fcb339584275acc290d2be9393ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7b63d7d9c4b4f35a4e999f2e177cbcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d4187bf2bd04b28a051e901a41f160d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f57a2720b21b46e492752e65b3e70470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97874ea40bce42c6838822a040bf7e80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5007898e6ccd4d0da057708174816cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JICHUCU1YmJ1","executionInfo":{"status":"ok","timestamp":1633561654368,"user_tz":-480,"elapsed":8656,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"d321c4d2-16e9-4bff-8ee3-bedbcabdff10"},"source":["#!pip install git+https://github.com/huggingface/nlp\n","!pip install transformers==2.11.0\n","!pip install nlp==0.2.0"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==2.11.0\n","  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n","\u001b[K     |████████████████████████████████| 674 kB 8.2 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (3.2.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 53.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2.23.0)\n","Collecting tokenizers==0.7.0\n","  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 23.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.7.0 transformers-2.11.0\n","Collecting nlp==0.2.0\n","  Downloading nlp-0.2.0-py3-none-any.whl (857 kB)\n","\u001b[K     |████████████████████████████████| 857 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (3.2.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (0.3.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (1.19.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp==0.2.0) (4.62.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2.10)\n","Installing collected packages: nlp\n","Successfully installed nlp-0.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"1NpkT01CZmBe","executionInfo":{"status":"ok","timestamp":1633561659222,"user_tz":-480,"elapsed":4858,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import transformers\n","import nlp\n","import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwmtKDccidm1","collapsed":true,"executionInfo":{"status":"ok","timestamp":1633561663239,"user_tz":-480,"elapsed":4032,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"cb7d0276-8d7a-41dc-a8ff-9aa892cd331e"},"source":["!pip install datasets==1.10.0"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==1.10.0\n","  Downloading datasets-1.10.0-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 10.0 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (1.1.5)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (0.3.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (21.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (1.19.5)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 63.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.0) (4.8.1)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 53.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.10.0) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.10.0) (3.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.10.0) (3.13)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.10.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.10.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.10.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.10.0) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.10.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.10.0) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.10.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.10.0) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.10.0) (1.15.0)\n","Installing collected packages: xxhash, huggingface-hub, fsspec, datasets\n","Successfully installed datasets-1.10.0 fsspec-2021.10.0 huggingface-hub-0.0.19 xxhash-2.0.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315,"referenced_widgets":["9f00116af98e48508bc4a1e1691e1a85","c3221c8581a547c5a7aad7411b55f5dc","2c16ef2863e54f52b654de849f78fb80","e6f64497c3024c22937058dd712c9f32","7384aaf85c0d45beb9666208362394a8","187ef0e2eb034f4c901ebf96c721f7cd","1fc08c1275af4c6eb7dc5ef9025bba5e","cf62791e398b4c17a17709c9202005f7","d013b4e6f7d74e4b9daf71b983b20cd6","8270cbe58c9d4078812de27b8e013c27","2dce3596e3914fd091dc5cdba816e536"]},"id":"0gAlfmBFtPVv","executionInfo":{"status":"ok","timestamp":1633561666801,"user_tz":-480,"elapsed":3565,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"dc459b68-6f97-4857-e156-01a4bebeaf66"},"source":["from datasets import load_dataset\n","from datasets import ReadInstruction\n","\"\"\"\n","dataset_dict = {\n","    \"cola\": load_dataset('glue','cola'),\n","    \"sst2\": load_dataset('glue','sst2')\n","}\n","\n","\"\"\"\n","dataset_dict = {\n","    \"wnli\": load_dataset('glue','wnli'),\n","    \"mrpc\": load_dataset('glue','mrpc')\n","}\n","\n","\"\"\"\n","_________________________\n","dataset_dict = {\n","    \"cola\": load_dataset('glue','cola'),\n","    \"sst2\": {\n","      'train': load_dataset('glue', 'sst2', split=ReadInstruction('train', from_=0, to=8551, unit='abs')),\n","      'test': load_dataset('glue', 'sst2', split=ReadInstruction('test')),\n","      'validation': load_dataset('glue', 'sst2', split=ReadInstruction('validation')),\n","    }\n","}\n","_________________________\n","dataset_dict = {\n","    \"cola\": load_dataset('glue','cola'),\n","    \"sst2\": load_dataset('glue', 'sst2', split=(ReadInstruction('train', from_=0, to=8551, unit='abs')+ReadInstruction('test')+ReadInstruction('validation'))),\n","}\n","\"\"\""],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f00116af98e48508bc4a1e1691e1a85","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77ee871583b946adac294fb23a40d0f1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset glue/wnli (download: 28.32 KiB, generated: 154.03 KiB, post-processed: Unknown size, total: 182.35 KiB) to /root/.cache/huggingface/datasets/glue/wnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7be1919abe648449e4f4c0b6282856c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca2ee79ab2194e7ca5afd487292fc970","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82875aef89034085a517535f68520362","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eeed66fff741413b8b9b0c61d33b9ab7","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/wnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f40f3c2dccd148759e8c1d2625782237","version_minor":0,"version_major":2},"text/plain":["Downloading: 0.00B [00:00, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a14dbb6ee78d4386be043ab37d657640","version_minor":0,"version_major":2},"text/plain":["Downloading: 0.00B [00:00, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2db775721c2e4b9eab3665e50157ad42","version_minor":0,"version_major":2},"text/plain":["Downloading: 0.00B [00:00, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79f4a5e8c6be46189c6d01b5cc22287b","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdd8471ab1844357bc8f8f12ea9a75d2","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38629de365a64c3dbf1179f96bfd797c","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n_________________________\\ndataset_dict = {\\n    \"cola\": load_dataset(\\'glue\\',\\'cola\\'),\\n    \"sst2\": {\\n      \\'train\\': load_dataset(\\'glue\\', \\'sst2\\', split=ReadInstruction(\\'train\\', from_=0, to=8551, unit=\\'abs\\')),\\n      \\'test\\': load_dataset(\\'glue\\', \\'sst2\\', split=ReadInstruction(\\'test\\')),\\n      \\'validation\\': load_dataset(\\'glue\\', \\'sst2\\', split=ReadInstruction(\\'validation\\')),\\n    }\\n}\\n_________________________\\ndataset_dict = {\\n    \"cola\": load_dataset(\\'glue\\',\\'cola\\'),\\n    \"sst2\": load_dataset(\\'glue\\', \\'sst2\\', split=(ReadInstruction(\\'train\\', from_=0, to=8551, unit=\\'abs\\')+ReadInstruction(\\'test\\')+ReadInstruction(\\'validation\\'))),\\n}\\n'"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4wl6zir7j8n","executionInfo":{"status":"ok","timestamp":1633561666802,"user_tz":-480,"elapsed":12,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"102e36cd-89c6-4f46-e6d7-5da15235a02e"},"source":["print(dataset_dict[\"wnli\"])\n","print(\"___________________\")\n","print(dataset_dict[\"mrpc\"])\n","print('___________________')\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 635\n","    })\n","    validation: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 71\n","    })\n","    test: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 146\n","    })\n","})\n","___________________\n","DatasetDict({\n","    train: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 3668\n","    })\n","    validation: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 408\n","    })\n","    test: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx'],\n","        num_rows: 1725\n","    })\n","})\n","___________________\n"]}]},{"cell_type":"code","metadata":{"id":"ALm4obXk7jP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633561666803,"user_tz":-480,"elapsed":9,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"baa8f019-2d31-45e8-866f-83cf36feab24"},"source":["for task_name, dataset in dataset_dict.items():\n","    print(task_name)\n","    print(dataset_dict[task_name][\"train\"][1])\n","    print()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["wnli\n","{'sentence1': \"John couldn't see the stage with Billy in front of him because he is so short.\", 'sentence2': 'John is so short.', 'label': 1, 'idx': 1}\n","\n","mrpc\n","{'sentence1': \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\", 'sentence2': \"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\", 'label': 0, 'idx': 1}\n","\n"]}]},{"cell_type":"code","metadata":{"id":"ReQF8v5E7oEj","executionInfo":{"status":"ok","timestamp":1633561667434,"user_tz":-480,"elapsed":12,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}}},"source":["class MultitaskModel(transformers.PreTrainedModel):\n","    def __init__(self, encoder, taskmodels_dict):\n","        super().__init__(transformers.PretrainedConfig())\n","\n","        self.encoder = encoder\n","        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n","\n","    @classmethod\n","    def create(cls, model_name, model_type_dict, model_config_dict):\n","        shared_encoder = None\n","        taskmodels_dict = {}\n","        for task_name, model_type in model_type_dict.items():\n","            model = model_type.from_pretrained(\n","                model_name, \n","                config=model_config_dict[task_name],\n","            )\n","            if shared_encoder is None:\n","                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n","            else:\n","                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n","            taskmodels_dict[task_name] = model\n","        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n","\n","    @classmethod\n","    def get_encoder_attr_name(cls, model):\n","        model_class_name = model.__class__.__name__\n","        if model_class_name.startswith(\"Bert\"):\n","            return \"bert\"\n","        elif model_class_name.startswith(\"Roberta\"):\n","            return \"roberta\"\n","        elif model_class_name.startswith(\"Albert\"):\n","            return \"albert\"\n","        else:\n","            raise KeyError(f\"Add support for new model {model_class_name}\")\n","\n","    def forward(self, task_name, **kwargs):\n","        return self.taskmodels_dict[task_name](**kwargs)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysWd9hsH7oym","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1633561685984,"user_tz":-480,"elapsed":18560,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"dac1d603-e302-4191-d8d2-7149badb0671"},"source":["model_name = \"roberta-base\"\n","multitask_model = MultitaskModel.create(\n","    model_name=model_name,\n","    model_type_dict={\n","        \"wnli\": transformers.AutoModelForSequenceClassification,\n","        \"mrpc\": transformers.AutoModelForSequenceClassification,\n","    },\n","    model_config_dict={\n","        \"wnli\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n","        \"mrpc\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n","    },\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp55tufbfc\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"341ba311b5df4d24ad9b1279ef490981","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","INFO:transformers.configuration_utils:Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","INFO:transformers.configuration_utils:Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:transformers.file_utils:https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpk1c7_j3_\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d91831045c841c787e7227e692b09f9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.file_utils:storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n"]}]},{"cell_type":"code","metadata":{"id":"66cHmIYi7q35","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633561685985,"user_tz":-480,"elapsed":12,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"ef70f6ae-2e84-4116-9371-e61a015ee0b1"},"source":["if model_name.startswith(\"roberta-\"):\n","    print(multitask_model.encoder.embeddings.word_embeddings.weight.data_ptr())\n","    print(multitask_model.taskmodels_dict[\"wnli\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n","    print(multitask_model.taskmodels_dict[\"mrpc\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n","else:\n","    print(\"Check model architecture =)\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["93829499731968\n","93829499731968\n","93829499731968\n"]}]},{"cell_type":"code","metadata":{"id":"CEcVs4a97vls","colab":{"base_uri":"https://localhost:8080/","height":618},"executionInfo":{"status":"ok","timestamp":1633561688017,"user_tz":-480,"elapsed":2039,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"3b131746-d3a7-4c98-c5a7-2f0a0a10e48c"},"source":["tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","INFO:transformers.configuration_utils:Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppiuaq0iw\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccf338d7fac94b05bb76ccfac813a925","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpofz8dk5d\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0650a7a2286e45afb0c7cf81913863a0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"]}]},{"cell_type":"code","metadata":{"id":"DpsRnj6Z7yU2","executionInfo":{"status":"ok","timestamp":1633561688018,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}}},"source":["max_length = 128\n","\n","def convert_to_2sen_features(example_batch):\n","    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n","    features = tokenizer.batch_encode_plus(\n","        inputs, max_length=max_length, pad_to_max_length=True\n","    )\n","    features[\"labels\"] = example_batch[\"label\"]\n","    return features\n","\n","def convert_to_1sen_features(example_batch):\n","    inputs = list(zip(example_batch['sentence']))\n","    features = tokenizer.batch_encode_plus(\n","        inputs, max_length=max_length, pad_to_max_length=True\n","    )\n","    features[\"labels\"] = example_batch[\"label\"]\n","    return features\n","\n","def convert_to_2que_features(example_batch):\n","    inputs = list(zip(example_batch['question1'], example_batch['question2']))\n","    features = tokenizer.batch_encode_plus(\n","        inputs, max_length=max_length, pad_to_max_length=True\n","    )\n","    features[\"labels\"] = example_batch[\"label\"]\n","    return features\n","\n","def convert_to_1que_features(example_batch):\n","    inputs = list(zip(example_batch['question']))\n","    features = tokenizer.batch_encode_plus(\n","        inputs, max_length=max_length, pad_to_max_length=True\n","    )\n","    features[\"labels\"] = example_batch[\"label\"]\n","    return features\n","\n","def convert_to_prehypo_features(example_batch):\n","    inputs = list(zip(example_batch['premise'], example_batch['hypothesis']))\n","    features = tokenizer.batch_encode_plus(\n","        inputs, max_length=max_length, pad_to_max_length=True\n","    )\n","    features[\"labels\"] = example_batch[\"label\"]\n","    return features\n","\n","convert_func_dict = {\n","    \"cola\": convert_to_1sen_features,\n","    \"stsb\": convert_to_2sen_features,\n","    \"rte\": convert_to_2sen_features,\n","    \"sst2\": convert_to_1sen_features,\n","    \"mrpc\": convert_to_2sen_features,\n","    \"qqp\": convert_to_2que_features,\n","    \"mnli\": convert_to_prehypo_features,\n","    \"qnli\": convert_to_1que_features,\n","    \"wnli\": convert_to_2sen_features,\n","}"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["64663b49094746ee9a279adee02818c5","dc2430b4c25247a0b0f8d9ed22113c99","84099942eb80488699684742ad8e5791","ee8bd466c2c74124b5b8e08c3cd88e38","d0ade1011e3d45e597465e6337bbf7d9","237011ca2b604433b2b18d8612198245","0f54704fc3204ca79f110d107aaf7cc5","04d1cae2d98c48169a9256cba4d094c8","7ccb7d8eb45049efbe25740e01f6ca5a","7667b55ec10e4a7491d64d44a3d46bbc","878d7a772e5f4b12aaaf618e96b2d3de"]},"id":"cgMNu-hCvOB3","executionInfo":{"status":"ok","timestamp":1633561697719,"user_tz":-480,"elapsed":9705,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"972e4113-577a-4bb8-f662-ae90c583e313"},"source":["columns_dict = {\n","    \"wnli\": ['input_ids', 'attention_mask', 'labels'],\n","    \"mrpc\": ['input_ids', 'attention_mask', 'labels'],\n","}\n","\n","features_dict = {}\n","for task_name, dataset in dataset_dict.items():\n","    features_dict[task_name] = {}\n","    for phase, phase_dataset in dataset.items():\n","        features_dict[task_name][phase] = phase_dataset.map(\n","            convert_func_dict[task_name],\n","            batched=True,\n","            load_from_cache_file=False,\n","        )\n","        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n","        features_dict[task_name][phase].set_format(\n","            type=\"torch\", \n","            columns=columns_dict[task_name],\n","        )\n","        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64663b49094746ee9a279adee02818c5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["wnli train 635 635\n","wnli train 635 635\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddb448f182dd4f0c8e1cda9ddc6476e2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["wnli validation 71 71\n","wnli validation 71 71\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa5efdbaa1f44dc38c347c530c6cf77f","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["wnli test 146 146\n","wnli test 146 146\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"620ff6c6c79f4335bb105e63c5b7a36a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["mrpc train 3668 3668\n","mrpc train 3668 3668\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07819ba5a5ff4ca79ff1da93c6bc7200","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["mrpc validation 408 408\n","mrpc validation 408 408\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dcded246bc24f6388850b1d2456fb0c","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["mrpc test 1725 1725\n","mrpc test 1725 1725\n"]}]},{"cell_type":"code","metadata":{"id":"RV8UrmBlD9aV","executionInfo":{"status":"ok","timestamp":1633561698331,"user_tz":-480,"elapsed":625,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}}},"source":["import dataclasses\n","from torch.utils.data.dataloader import DataLoader\n","from transformers.training_args import is_tpu_available\n","from transformers.trainer import get_tpu_sampler\n","from transformers.data.data_collator import DataCollator, InputDataClass\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.utils.data.sampler import RandomSampler\n","from typing import List, Union, Dict\n","\n","\n","class NLPDataCollator(DataCollator):\n","    \"\"\"\n","    Extending the existing DataCollator to work with NLP dataset batches\n","    \"\"\"\n","    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n","        first = features[0]\n","        if isinstance(first, dict):\n","          # NLP data sets current works presents features as lists of dictionary\n","          # (one per example), so we  will adapt the collate_batch logic for that\n","          if \"labels\" in first and first[\"labels\"] is not None:\n","              if first[\"labels\"].dtype == torch.int64:\n","                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n","              else:\n","                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n","              batch = {\"labels\": labels}\n","          for k, v in first.items():\n","              if k != \"labels\" and v is not None and not isinstance(v, str):\n","                  batch[k] = torch.stack([f[k] for f in features])\n","          return batch\n","        else:\n","          # otherwise, revert to using the default collate_batch\n","          return DefaultDataCollator().collate_batch(features)\n","\n","\n","class StrIgnoreDevice(str):\n","    def to(self, device):\n","        return self\n","\n","\n","class DataLoaderWithTaskname:\n","    def __init__(self, task_name, data_loader):\n","        self.task_name = task_name\n","        self.data_loader = data_loader\n","\n","        self.batch_size = data_loader.batch_size\n","        self.dataset = data_loader.dataset\n","\n","    def __len__(self):\n","        return len(self.data_loader)\n","    \n","    def __iter__(self):\n","        for batch in self.data_loader:\n","            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n","            yield batch\n","\n","\n","class MultitaskDataloader:\n","    \"\"\"\n","    Data loader that combines and samples from multiple single-task\n","    data loaders.\n","    \"\"\"\n","    def __init__(self, dataloader_dict):\n","        self.dataloader_dict = dataloader_dict\n","        self.num_batches_dict = {\n","            task_name: len(dataloader) \n","            for task_name, dataloader in self.dataloader_dict.items()\n","        }\n","        self.task_name_list = list(self.dataloader_dict)\n","        self.dataset = [None] * sum(\n","            len(dataloader.dataset) \n","            for dataloader in self.dataloader_dict.values()\n","        )\n","\n","    def __len__(self):\n","        return sum(self.num_batches_dict.values())\n","\n","    def __iter__(self):\n","        \"\"\"\n","        For each batch, sample a task, and yield a batch from the respective\n","        task Dataloader.\n","\n","        We use size-proportional sampling, but you could easily modify this\n","        to sample from some-other distribution.\n","        \"\"\"\n","        task_choice_list = []\n","        for i, task_name in enumerate(self.task_name_list):\n","            task_choice_list += [i] * self.num_batches_dict[task_name]\n","        task_choice_list = np.array(task_choice_list)\n","        np.random.shuffle(task_choice_list)\n","        dataloader_iter_dict = {\n","            task_name: iter(dataloader) \n","            for task_name, dataloader in self.dataloader_dict.items()\n","        }\n","        for task_choice in task_choice_list:\n","            task_name = self.task_name_list[task_choice]\n","            yield next(dataloader_iter_dict[task_name])    \n","\n","class MultitaskTrainer(transformers.Trainer):\n","\n","    def get_single_train_dataloader(self, task_name, train_dataset):\n","        \"\"\"\n","        Create a single-task data loader that also yields task names\n","        \"\"\"\n","        if self.train_dataset is None:\n","            raise ValueError(\"Trainer: training requires a train_dataset.\")\n","        if is_tpu_available():\n","            train_sampler = get_tpu_sampler(train_dataset)\n","        else:\n","            train_sampler = (\n","                RandomSampler(train_dataset)\n","                if self.args.local_rank == -1\n","                else DistributedSampler(train_dataset)\n","            )\n","\n","        data_loader = DataLoaderWithTaskname(\n","            task_name=task_name,\n","            data_loader=DataLoader(\n","              train_dataset,\n","              batch_size=self.args.train_batch_size,\n","              sampler=train_sampler,\n","              collate_fn=self.data_collator.collate_batch,\n","            ),\n","        )\n","\n","        if is_tpu_available():\n","            data_loader = pl.ParallelLoader(\n","                data_loader, [self.args.device]\n","            ).per_device_loader(self.args.device)\n","        return data_loader\n","\n","    def get_train_dataloader(self):\n","        \"\"\"\n","        Returns a MultitaskDataloader, which is not actually a Dataloader\n","        but an iterable that returns a generator that samples from each \n","        task Dataloader\n","        \"\"\"\n","        return MultitaskDataloader({\n","            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n","            for task_name, task_dataset in self.train_dataset.items()\n","        })"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzGbpWNXE7ig","colab":{"base_uri":"https://localhost:8080/","height":663,"referenced_widgets":["1cbefa5229f24885a846f41a70051e03","a8a9d8a7950f4a10947694dc0502ba8a","1176bb6efa364ec78904bd1f86620253","b9e52956c6df4efa974a6e6f69c96d63","5543e4ca4c0a4c7a839abf1259456ecd","3b846418ad514b48b2de6f8ea47625ce","f97835a89799477486d39c4ceae4eb0e","c4813290fc294acfa98d228284c1a6d2","e1f23bdc605c40e9b41c02345ca7eb5d","215806e166e54950a4b2fc3dfb81a368","94845e7b34234da4ae9ae41d65f69a53","03642103586a428180c63d1e39422e4f","9c5dcc6c59f54366ad98308d4da7ab4a","0882a52ffcfd41abb5ac64428434a598","bf3f7ba5ef6f4276a3f8f4ebb0d731d2","e554e99b59924b419bcb1ccd318bd933","7b372cc9a64c47339dd8d89066b3ea8b","af95cc3a9e3245cab4cf9cab0b665a05","3640993c13764216b859778613b410e8","fb8c794f3ba544dab5b686223d033df2","f0b3baa699484437a82b8b10b0a0221b","59b6f84155cd47179d82435acd4b0abe"]},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1633562246101,"user_tz":-480,"elapsed":547773,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"08c1425f-1b51-49a0-ff92-199dc232ac82"},"source":["train_dataset = {\n","    task_name: dataset[\"train\"] \n","    for task_name, dataset in features_dict.items()\n","}\n","trainer = MultitaskTrainer(\n","    model=multitask_model,\n","    args=transformers.TrainingArguments(\n","        output_dir=\"./models/multitask_model\",\n","        overwrite_output_dir=True,\n","        learning_rate=2e-5,\n","        do_train=True,\n","        num_train_epochs=10,\n","        # Adjust batch size if this doesn't fit on the Colab GPU\n","        per_device_train_batch_size=32, \n","        save_steps=3000, \n","    ),\n","    data_collator=NLPDataCollator(),\n","    train_dataset=train_dataset,\n",")\n","trainer.train()\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:transformers.training_args:PyTorch: setting up devices\n","INFO:transformers.trainer:You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n","INFO:transformers.trainer:***** Running training *****\n","INFO:transformers.trainer:  Num examples = 4303\n","INFO:transformers.trainer:  Num Epochs = 10\n","INFO:transformers.trainer:  Instantaneous batch size per device = 32\n","INFO:transformers.trainer:  Total train batch size (w. parallel, distributed & accumulation) = 32\n","INFO:transformers.trainer:  Gradient Accumulation steps = 1\n","INFO:transformers.trainer:  Total optimization steps = 1350\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cbefa5229f24885a846f41a70051e03","version_minor":0,"version_major":2},"text/plain":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03642103586a428180c63d1e39422e4f","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef3187e4ebf04998813c686a0055a1d1","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6cd1434649a4f4cbb372affd5128603","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24bd8da3f98c4dc780e050107648ad2e","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{\"loss\": 0.38992876167409124, \"learning_rate\": 1.2592592592592593e-05, \"epoch\": 3.7037037037037037, \"step\": 500}\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc84995a218043d090e21bad4eb1a0aa","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23fa49e5fbc742b187bc3288509ac952","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d747153e50194a618da2845b48d70531","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71101e7b7e43431d91424508f61d280e","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{\"loss\": 0.17897812982345931, \"learning_rate\": 5.185185185185185e-06, \"epoch\": 7.407407407407407, \"step\": 1000}\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf70d58f5a354c33a9445e31db6b8403","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1857268f90a848029a23a4bac58ee1f1","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.trainer:\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1350, training_loss=0.24564810693539954)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"-iq9nI57FXTs","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"ok","timestamp":1633562249213,"user_tz":-480,"elapsed":3123,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"652507ce-4ff9-4bd5-fb71-6b9eb1689d21"},"source":["preds_dict = {}\n","for task_name in [\"wnli\", \"mrpc\"]:\n","    eval_dataloader = DataLoaderWithTaskname(\n","        task_name,\n","        trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\n","    )\n","    print(eval_dataloader.data_loader.collate_fn)\n","    preds_dict[task_name] = trainer._prediction_loop(\n","        eval_dataloader, \n","        description=f\"Validation: {task_name}\",\n","    )"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:transformers.trainer:***** Running Validation: wnli *****\n","INFO:transformers.trainer:  Num examples = 71\n","INFO:transformers.trainer:  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7ffa270fa550>>\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"497def3e75be48a49b823bfd04420056","version_minor":0,"version_major":2},"text/plain":["Validation: wnli:   0%|          | 0/9 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:transformers.trainer:***** Running Validation: mrpc *****\n","INFO:transformers.trainer:  Num examples = 408\n","INFO:transformers.trainer:  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7ffa270fa550>>\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e38117c0e20a42629c0a5894f51552e6","version_minor":0,"version_major":2},"text/plain":["Validation: mrpc:   0%|          | 0/51 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"V4FaN1jBFc0Y","colab":{"base_uri":"https://localhost:8080/","height":258,"referenced_widgets":["cd142ea1bc08489bb07faa2d2e3551b6","3568f3b6fd54465aa74eff13c381fc25","81b2a8812c3840be9408a4f51c9a8e5f","1d47186eb8ff42699b04b9a4a3aa9584","1e6340e29f094983818e12839502de92","fc92fcb339584275acc290d2be9393ca","b7b63d7d9c4b4f35a4e999f2e177cbcd","9d4187bf2bd04b28a051e901a41f160d","f57a2720b21b46e492752e65b3e70470","97874ea40bce42c6838822a040bf7e80","5007898e6ccd4d0da057708174816cf0"]},"executionInfo":{"status":"ok","timestamp":1633562249635,"user_tz":-480,"elapsed":432,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"5a06cf1e-1717-4feb-f67b-f5c743667248"},"source":["# Evalute wnli\n","nlp.load_metric('glue', name=\"wnli\").compute(\n","    np.argmax(preds_dict[\"wnli\"].predictions, axis=1),\n","    preds_dict[\"wnli\"].label_ids,\n",")"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:nlp.utils.file_utils:https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/tmpbeeq62yu\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd142ea1bc08489bb07faa2d2e3551b6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/4.15k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:nlp.utils.file_utils:storing https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py in cache at /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py\n","INFO:nlp.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py\n","INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py for additional imports.\n","INFO:nlp.load:Creating main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue\n","INFO:nlp.load:Creating specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68\n","INFO:nlp.load:Copying script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py to /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.py\n","INFO:nlp.load:Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/dataset_infos.json\n","INFO:nlp.load:Creating metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.json\n","INFO:nlp.arrow_writer:Done writing 71 examples in 1136 bytes /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.\n","INFO:nlp.arrow_dataset:Set __getitem__(key) output type to numpy for no columns  (when key is int or slice) and don't output other (un-formated) columns.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.2535211267605634}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"XKZmfuUyFX4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633562250646,"user_tz":-480,"elapsed":1013,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}},"outputId":"be4c684a-e5d9-4acf-b25c-b19192fc3ae8"},"source":["# Evalute mrpc\n","nlp.load_metric('glue', name=\"mrpc\").compute(\n","    np.argmax(preds_dict[\"mrpc\"].predictions, axis=1),\n","    preds_dict[\"mrpc\"].label_ids,\n",")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py for additional imports.\n","INFO:nlp.load:Found main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue\n","INFO:nlp.load:Found specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68\n","INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py to /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.py\n","INFO:nlp.load:Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/dataset_infos.json\n","INFO:nlp.load:Found metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.7/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.json\n","INFO:nlp.arrow_writer:Done writing 408 examples in 6528 bytes /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.\n","INFO:nlp.arrow_dataset:Set __getitem__(key) output type to numpy for no columns  (when key is int or slice) and don't output other (un-formated) columns.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.8799019607843137, 'f1': 0.9129662522202486}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"YO64L6vfFdn_","executionInfo":{"status":"ok","timestamp":1633562250647,"user_tz":-480,"elapsed":7,"user":{"displayName":"Ecalpal L","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18088371448594638196"}}},"source":[""],"execution_count":17,"outputs":[]}]}